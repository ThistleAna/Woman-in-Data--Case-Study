{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car Sales-RNNModels",
      "provenance": [],
      "authorship_tag": "ABX9TyPBvDY4VCyMgMX8eBSlDcA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThistleAna/snowflakes/blob/main/Car_Sales_RNNModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3X-a6-4w8Hf"
      },
      "source": [
        "# Recurrent Neural Network Models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMhqCnhkx2m6",
        "outputId": "58a76ff9-ff9a-44b3-e718-4c35254f84ba"
      },
      "source": [
        "# lstm for time series forecasting\r\n",
        "from numpy import sqrt\r\n",
        "from numpy import asarray\r\n",
        "from pandas import read_csv\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "\r\n",
        "# split a univariate sequence into samples\r\n",
        "def split_sequence(sequence, n_steps):\r\n",
        "\tX, y = list(), list()\r\n",
        "\tfor i in range(len(sequence)):\r\n",
        "\t\t# find the end of this pattern\r\n",
        "\t\tend_ix = i + n_steps\r\n",
        "\t\t# check if we are beyond the sequence\r\n",
        "\t\tif end_ix > len(sequence)-1:\r\n",
        "\t\t\tbreak\r\n",
        "\t\t# gather input and output parts of the pattern\r\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\r\n",
        "\t\tX.append(seq_x)\r\n",
        "\t\ty.append(seq_y)\r\n",
        "\treturn asarray(X), asarray(y)\r\n",
        "\r\n",
        "# load the dataset\r\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\r\n",
        "df = read_csv(path, header=0, index_col=0, squeeze=True)\r\n",
        "# retrieve the values\r\n",
        "values = df.values.astype('float32')\r\n",
        "# specify the window size\r\n",
        "n_steps = 5\r\n",
        "# split into samples\r\n",
        "X, y = split_sequence(values, n_steps)\r\n",
        "# reshape into [samples, timesteps, features]\r\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\r\n",
        "# split into train/test\r\n",
        "n_test = 12\r\n",
        "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\r\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\r\n",
        "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\r\n",
        "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\r\n",
        "model.add(Dense(1))\r\n",
        "# compile the model\r\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\r\n",
        "# fit the model\r\n",
        "model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))\r\n",
        "# evaluate the model\r\n",
        "mse, mae = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))\r\n",
        "# make a prediction\r\n",
        "row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\r\n",
        "yhat = model.predict(row)\r\n",
        "print('Predicted: %.3f' % (yhat))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91, 5, 1) (12, 5, 1) (91,) (12,)\n",
            "Epoch 1/350\n",
            "3/3 - 2s - loss: 166373952.0000 - mae: 11326.9160 - val_loss: 108694104.0000 - val_mae: 8704.3115\n",
            "Epoch 2/350\n",
            "3/3 - 0s - loss: 50155904.0000 - mae: 5721.9194 - val_loss: 22828726.0000 - val_mae: 3959.0286\n",
            "Epoch 3/350\n",
            "3/3 - 0s - loss: 31698410.0000 - mae: 4606.4438 - val_loss: 28333682.0000 - val_mae: 4675.4888\n",
            "Epoch 4/350\n",
            "3/3 - 0s - loss: 27504572.0000 - mae: 4032.8513 - val_loss: 16035743.0000 - val_mae: 2672.7239\n",
            "Epoch 5/350\n",
            "3/3 - 0s - loss: 29320388.0000 - mae: 4143.1011 - val_loss: 38967328.0000 - val_mae: 4046.2004\n",
            "Epoch 6/350\n",
            "3/3 - 0s - loss: 24648436.0000 - mae: 3755.7788 - val_loss: 32085440.0000 - val_mae: 3835.5430\n",
            "Epoch 7/350\n",
            "3/3 - 0s - loss: 18616268.0000 - mae: 3335.2019 - val_loss: 26093286.0000 - val_mae: 3628.4463\n",
            "Epoch 8/350\n",
            "3/3 - 0s - loss: 17898422.0000 - mae: 3349.0293 - val_loss: 19223706.0000 - val_mae: 3459.3674\n",
            "Epoch 9/350\n",
            "3/3 - 0s - loss: 15466708.0000 - mae: 3169.3269 - val_loss: 18532400.0000 - val_mae: 3324.3145\n",
            "Epoch 10/350\n",
            "3/3 - 0s - loss: 14780520.0000 - mae: 3061.7864 - val_loss: 21584666.0000 - val_mae: 3522.4307\n",
            "Epoch 11/350\n",
            "3/3 - 0s - loss: 14875469.0000 - mae: 3094.6965 - val_loss: 12044303.0000 - val_mae: 2646.9236\n",
            "Epoch 12/350\n",
            "3/3 - 0s - loss: 12962847.0000 - mae: 2879.8347 - val_loss: 10289870.0000 - val_mae: 2511.9941\n",
            "Epoch 13/350\n",
            "3/3 - 0s - loss: 12349486.0000 - mae: 2858.9521 - val_loss: 11530616.0000 - val_mae: 2905.5383\n",
            "Epoch 14/350\n",
            "3/3 - 0s - loss: 11745637.0000 - mae: 2724.0554 - val_loss: 10673632.0000 - val_mae: 2652.2654\n",
            "Epoch 15/350\n",
            "3/3 - 0s - loss: 11002202.0000 - mae: 2643.0281 - val_loss: 10383824.0000 - val_mae: 2507.3831\n",
            "Epoch 16/350\n",
            "3/3 - 0s - loss: 12091272.0000 - mae: 2741.3979 - val_loss: 13591807.0000 - val_mae: 2984.1316\n",
            "Epoch 17/350\n",
            "3/3 - 0s - loss: 11908254.0000 - mae: 2709.5767 - val_loss: 8890232.0000 - val_mae: 2362.8135\n",
            "Epoch 18/350\n",
            "3/3 - 0s - loss: 10895807.0000 - mae: 2649.6895 - val_loss: 10220567.0000 - val_mae: 2308.1375\n",
            "Epoch 19/350\n",
            "3/3 - 0s - loss: 11829716.0000 - mae: 2808.3513 - val_loss: 17971226.0000 - val_mae: 3266.3743\n",
            "Epoch 20/350\n",
            "3/3 - 0s - loss: 11270868.0000 - mae: 2605.4866 - val_loss: 16384415.0000 - val_mae: 3072.7969\n",
            "Epoch 21/350\n",
            "3/3 - 0s - loss: 11383790.0000 - mae: 2609.3440 - val_loss: 15854469.0000 - val_mae: 3357.6707\n",
            "Epoch 22/350\n",
            "3/3 - 0s - loss: 12137208.0000 - mae: 2695.7473 - val_loss: 14057328.0000 - val_mae: 2907.1091\n",
            "Epoch 23/350\n",
            "3/3 - 0s - loss: 11469753.0000 - mae: 2674.9434 - val_loss: 14861984.0000 - val_mae: 2963.2148\n",
            "Epoch 24/350\n",
            "3/3 - 0s - loss: 11866641.0000 - mae: 2687.1951 - val_loss: 14212611.0000 - val_mae: 3023.1409\n",
            "Epoch 25/350\n",
            "3/3 - 0s - loss: 11982789.0000 - mae: 2690.2568 - val_loss: 14151137.0000 - val_mae: 3059.5498\n",
            "Epoch 26/350\n",
            "3/3 - 0s - loss: 11706970.0000 - mae: 2635.3301 - val_loss: 13890404.0000 - val_mae: 3135.7852\n",
            "Epoch 27/350\n",
            "3/3 - 0s - loss: 13734788.0000 - mae: 2751.2063 - val_loss: 14352185.0000 - val_mae: 3112.6140\n",
            "Epoch 28/350\n",
            "3/3 - 0s - loss: 13271589.0000 - mae: 2778.5425 - val_loss: 13816941.0000 - val_mae: 3143.0000\n",
            "Epoch 29/350\n",
            "3/3 - 0s - loss: 12520442.0000 - mae: 2685.8237 - val_loss: 15583133.0000 - val_mae: 3393.9893\n",
            "Epoch 30/350\n",
            "3/3 - 0s - loss: 12365704.0000 - mae: 2668.3586 - val_loss: 15914817.0000 - val_mae: 3439.1531\n",
            "Epoch 31/350\n",
            "3/3 - 0s - loss: 11800480.0000 - mae: 2667.7781 - val_loss: 14967785.0000 - val_mae: 3416.6003\n",
            "Epoch 32/350\n",
            "3/3 - 0s - loss: 11387663.0000 - mae: 2688.0408 - val_loss: 14691972.0000 - val_mae: 3275.4675\n",
            "Epoch 33/350\n",
            "3/3 - 0s - loss: 10378066.0000 - mae: 2443.8696 - val_loss: 16716228.0000 - val_mae: 3369.4490\n",
            "Epoch 34/350\n",
            "3/3 - 0s - loss: 10298240.0000 - mae: 2467.9980 - val_loss: 14842589.0000 - val_mae: 3257.0322\n",
            "Epoch 35/350\n",
            "3/3 - 0s - loss: 10503306.0000 - mae: 2562.1438 - val_loss: 14877437.0000 - val_mae: 3317.4539\n",
            "Epoch 36/350\n",
            "3/3 - 0s - loss: 10198841.0000 - mae: 2533.4980 - val_loss: 14876851.0000 - val_mae: 3258.0085\n",
            "Epoch 37/350\n",
            "3/3 - 0s - loss: 10161791.0000 - mae: 2456.6333 - val_loss: 15760408.0000 - val_mae: 3300.9893\n",
            "Epoch 38/350\n",
            "3/3 - 0s - loss: 10087226.0000 - mae: 2428.2844 - val_loss: 14436539.0000 - val_mae: 3258.8640\n",
            "Epoch 39/350\n",
            "3/3 - 0s - loss: 9231575.0000 - mae: 2392.1433 - val_loss: 15182741.0000 - val_mae: 3257.5359\n",
            "Epoch 40/350\n",
            "3/3 - 0s - loss: 9249757.0000 - mae: 2320.8110 - val_loss: 16219844.0000 - val_mae: 3208.7861\n",
            "Epoch 41/350\n",
            "3/3 - 0s - loss: 10364139.0000 - mae: 2477.9543 - val_loss: 11264309.0000 - val_mae: 2660.9246\n",
            "Epoch 42/350\n",
            "3/3 - 0s - loss: 9880469.0000 - mae: 2447.3755 - val_loss: 12501776.0000 - val_mae: 2844.8904\n",
            "Epoch 43/350\n",
            "3/3 - 0s - loss: 9510372.0000 - mae: 2410.0217 - val_loss: 12852247.0000 - val_mae: 2891.1951\n",
            "Epoch 44/350\n",
            "3/3 - 0s - loss: 9771042.0000 - mae: 2419.4055 - val_loss: 12844752.0000 - val_mae: 2881.8293\n",
            "Epoch 45/350\n",
            "3/3 - 0s - loss: 9684731.0000 - mae: 2366.1475 - val_loss: 12993713.0000 - val_mae: 3027.0039\n",
            "Epoch 46/350\n",
            "3/3 - 0s - loss: 9355581.0000 - mae: 2371.6670 - val_loss: 10996988.0000 - val_mae: 2766.8164\n",
            "Epoch 47/350\n",
            "3/3 - 0s - loss: 8842741.0000 - mae: 2273.4390 - val_loss: 10623515.0000 - val_mae: 2491.6985\n",
            "Epoch 48/350\n",
            "3/3 - 0s - loss: 9391636.0000 - mae: 2363.3245 - val_loss: 11138199.0000 - val_mae: 2686.3154\n",
            "Epoch 49/350\n",
            "3/3 - 0s - loss: 8120041.5000 - mae: 2201.0903 - val_loss: 12213672.0000 - val_mae: 2696.2146\n",
            "Epoch 50/350\n",
            "3/3 - 0s - loss: 7967893.0000 - mae: 2156.5044 - val_loss: 10979784.0000 - val_mae: 2563.0635\n",
            "Epoch 51/350\n",
            "3/3 - 0s - loss: 7975820.0000 - mae: 2183.9060 - val_loss: 11273424.0000 - val_mae: 2695.2056\n",
            "Epoch 52/350\n",
            "3/3 - 0s - loss: 8081275.0000 - mae: 2189.6704 - val_loss: 11749797.0000 - val_mae: 2663.3057\n",
            "Epoch 53/350\n",
            "3/3 - 0s - loss: 8256100.0000 - mae: 2144.8879 - val_loss: 10728772.0000 - val_mae: 2647.3901\n",
            "Epoch 54/350\n",
            "3/3 - 0s - loss: 7787995.5000 - mae: 2086.3132 - val_loss: 12086371.0000 - val_mae: 2922.0535\n",
            "Epoch 55/350\n",
            "3/3 - 0s - loss: 8800637.0000 - mae: 2267.6523 - val_loss: 12944581.0000 - val_mae: 2912.5400\n",
            "Epoch 56/350\n",
            "3/3 - 0s - loss: 8771336.0000 - mae: 2199.6682 - val_loss: 13755783.0000 - val_mae: 2739.0935\n",
            "Epoch 57/350\n",
            "3/3 - 0s - loss: 9023458.0000 - mae: 2294.4517 - val_loss: 12440917.0000 - val_mae: 2749.0566\n",
            "Epoch 58/350\n",
            "3/3 - 0s - loss: 8722533.0000 - mae: 2299.4282 - val_loss: 14022885.0000 - val_mae: 3211.8015\n",
            "Epoch 59/350\n",
            "3/3 - 0s - loss: 9682810.0000 - mae: 2399.3638 - val_loss: 14620413.0000 - val_mae: 2823.4561\n",
            "Epoch 60/350\n",
            "3/3 - 0s - loss: 9255036.0000 - mae: 2301.9397 - val_loss: 13888165.0000 - val_mae: 2936.4080\n",
            "Epoch 61/350\n",
            "3/3 - 0s - loss: 8987705.0000 - mae: 2282.0469 - val_loss: 12599541.0000 - val_mae: 2793.8835\n",
            "Epoch 62/350\n",
            "3/3 - 0s - loss: 9461321.0000 - mae: 2400.1619 - val_loss: 14668515.0000 - val_mae: 2900.5342\n",
            "Epoch 63/350\n",
            "3/3 - 0s - loss: 8639761.0000 - mae: 2262.7100 - val_loss: 15728680.0000 - val_mae: 2954.1533\n",
            "Epoch 64/350\n",
            "3/3 - 0s - loss: 10526958.0000 - mae: 2375.5957 - val_loss: 18101846.0000 - val_mae: 3084.6775\n",
            "Epoch 65/350\n",
            "3/3 - 0s - loss: 10538756.0000 - mae: 2517.8572 - val_loss: 13889792.0000 - val_mae: 3029.7822\n",
            "Epoch 66/350\n",
            "3/3 - 0s - loss: 9574056.0000 - mae: 2365.3574 - val_loss: 14019973.0000 - val_mae: 2925.0068\n",
            "Epoch 67/350\n",
            "3/3 - 0s - loss: 9589043.0000 - mae: 2359.0134 - val_loss: 13841692.0000 - val_mae: 2916.1277\n",
            "Epoch 68/350\n",
            "3/3 - 0s - loss: 9827687.0000 - mae: 2416.3035 - val_loss: 13131323.0000 - val_mae: 2909.6648\n",
            "Epoch 69/350\n",
            "3/3 - 0s - loss: 9659274.0000 - mae: 2404.6501 - val_loss: 14003856.0000 - val_mae: 2902.9714\n",
            "Epoch 70/350\n",
            "3/3 - 0s - loss: 9796933.0000 - mae: 2428.0474 - val_loss: 13766527.0000 - val_mae: 2901.4307\n",
            "Epoch 71/350\n",
            "3/3 - 0s - loss: 8976365.0000 - mae: 2309.3032 - val_loss: 12184647.0000 - val_mae: 2794.2952\n",
            "Epoch 72/350\n",
            "3/3 - 0s - loss: 8968295.0000 - mae: 2314.5776 - val_loss: 11603673.0000 - val_mae: 2708.4409\n",
            "Epoch 73/350\n",
            "3/3 - 0s - loss: 8750716.0000 - mae: 2266.6921 - val_loss: 12517213.0000 - val_mae: 2730.9602\n",
            "Epoch 74/350\n",
            "3/3 - 0s - loss: 8440890.0000 - mae: 2239.3657 - val_loss: 11084763.0000 - val_mae: 2722.4053\n",
            "Epoch 75/350\n",
            "3/3 - 0s - loss: 8484343.0000 - mae: 2295.6313 - val_loss: 11618563.0000 - val_mae: 2767.4407\n",
            "Epoch 76/350\n",
            "3/3 - 0s - loss: 8248121.0000 - mae: 2270.8225 - val_loss: 12840912.0000 - val_mae: 2838.3333\n",
            "Epoch 77/350\n",
            "3/3 - 0s - loss: 8708811.0000 - mae: 2247.7786 - val_loss: 11676624.0000 - val_mae: 2760.9001\n",
            "Epoch 78/350\n",
            "3/3 - 0s - loss: 8895257.0000 - mae: 2354.5994 - val_loss: 11965383.0000 - val_mae: 2823.6062\n",
            "Epoch 79/350\n",
            "3/3 - 0s - loss: 9522027.0000 - mae: 2513.8394 - val_loss: 14108663.0000 - val_mae: 2938.6750\n",
            "Epoch 80/350\n",
            "3/3 - 0s - loss: 8774900.0000 - mae: 2313.9675 - val_loss: 11606384.0000 - val_mae: 2744.4805\n",
            "Epoch 81/350\n",
            "3/3 - 0s - loss: 8515882.0000 - mae: 2328.2107 - val_loss: 11716240.0000 - val_mae: 2778.0515\n",
            "Epoch 82/350\n",
            "3/3 - 0s - loss: 8702323.0000 - mae: 2288.2932 - val_loss: 12540995.0000 - val_mae: 2825.4050\n",
            "Epoch 83/350\n",
            "3/3 - 0s - loss: 8020815.0000 - mae: 2210.7769 - val_loss: 11386883.0000 - val_mae: 2677.4580\n",
            "Epoch 84/350\n",
            "3/3 - 0s - loss: 8584444.0000 - mae: 2362.2896 - val_loss: 11582264.0000 - val_mae: 2715.0764\n",
            "Epoch 85/350\n",
            "3/3 - 0s - loss: 8236559.5000 - mae: 2193.1594 - val_loss: 13130693.0000 - val_mae: 2848.1970\n",
            "Epoch 86/350\n",
            "3/3 - 0s - loss: 8203177.0000 - mae: 2227.5364 - val_loss: 11327003.0000 - val_mae: 2671.8679\n",
            "Epoch 87/350\n",
            "3/3 - 0s - loss: 8356701.5000 - mae: 2324.9436 - val_loss: 11197168.0000 - val_mae: 2653.5518\n",
            "Epoch 88/350\n",
            "3/3 - 0s - loss: 8085961.0000 - mae: 2241.7502 - val_loss: 12907375.0000 - val_mae: 2845.1863\n",
            "Epoch 89/350\n",
            "3/3 - 0s - loss: 7938700.5000 - mae: 2189.2859 - val_loss: 11064371.0000 - val_mae: 2601.4741\n",
            "Epoch 90/350\n",
            "3/3 - 0s - loss: 7955644.5000 - mae: 2258.8271 - val_loss: 11076252.0000 - val_mae: 2624.7854\n",
            "Epoch 91/350\n",
            "3/3 - 0s - loss: 7783498.0000 - mae: 2178.4180 - val_loss: 11704995.0000 - val_mae: 2708.5798\n",
            "Epoch 92/350\n",
            "3/3 - 0s - loss: 7708620.0000 - mae: 2177.3394 - val_loss: 11010364.0000 - val_mae: 2601.4785\n",
            "Epoch 93/350\n",
            "3/3 - 0s - loss: 7812758.0000 - mae: 2235.5388 - val_loss: 11005079.0000 - val_mae: 2602.8877\n",
            "Epoch 94/350\n",
            "3/3 - 0s - loss: 8082053.0000 - mae: 2251.3799 - val_loss: 11859013.0000 - val_mae: 2757.6472\n",
            "Epoch 95/350\n",
            "3/3 - 0s - loss: 8004822.0000 - mae: 2256.8667 - val_loss: 10618099.0000 - val_mae: 2493.2385\n",
            "Epoch 96/350\n",
            "3/3 - 0s - loss: 7557010.5000 - mae: 2190.3640 - val_loss: 11457656.0000 - val_mae: 2675.8040\n",
            "Epoch 97/350\n",
            "3/3 - 0s - loss: 7963692.5000 - mae: 2186.4580 - val_loss: 10978029.0000 - val_mae: 2593.9756\n",
            "Epoch 98/350\n",
            "3/3 - 0s - loss: 7866160.0000 - mae: 2201.2954 - val_loss: 10578041.0000 - val_mae: 2499.7273\n",
            "Epoch 99/350\n",
            "3/3 - 0s - loss: 7544214.5000 - mae: 2190.6318 - val_loss: 10756529.0000 - val_mae: 2546.9265\n",
            "Epoch 100/350\n",
            "3/3 - 0s - loss: 7730932.5000 - mae: 2176.3042 - val_loss: 11471941.0000 - val_mae: 2696.1096\n",
            "Epoch 101/350\n",
            "3/3 - 0s - loss: 7357530.0000 - mae: 2134.7324 - val_loss: 10597231.0000 - val_mae: 2459.3718\n",
            "Epoch 102/350\n",
            "3/3 - 0s - loss: 8337910.0000 - mae: 2331.1960 - val_loss: 10687134.0000 - val_mae: 2543.1794\n",
            "Epoch 103/350\n",
            "3/3 - 0s - loss: 8022084.0000 - mae: 2206.4265 - val_loss: 12744525.0000 - val_mae: 2856.1614\n",
            "Epoch 104/350\n",
            "3/3 - 0s - loss: 7847628.0000 - mae: 2153.7080 - val_loss: 10882853.0000 - val_mae: 2544.6047\n",
            "Epoch 105/350\n",
            "3/3 - 0s - loss: 7870758.5000 - mae: 2258.8149 - val_loss: 11017992.0000 - val_mae: 2639.5173\n",
            "Epoch 106/350\n",
            "3/3 - 0s - loss: 7380940.0000 - mae: 2106.8516 - val_loss: 11596368.0000 - val_mae: 2736.1404\n",
            "Epoch 107/350\n",
            "3/3 - 0s - loss: 7341790.0000 - mae: 2113.9478 - val_loss: 10481600.0000 - val_mae: 2448.0916\n",
            "Epoch 108/350\n",
            "3/3 - 0s - loss: 7459549.5000 - mae: 2192.9707 - val_loss: 10477755.0000 - val_mae: 2448.9434\n",
            "Epoch 109/350\n",
            "3/3 - 0s - loss: 7352138.0000 - mae: 2136.9053 - val_loss: 11218944.0000 - val_mae: 2688.5505\n",
            "Epoch 110/350\n",
            "3/3 - 0s - loss: 7398418.5000 - mae: 2127.3926 - val_loss: 10519164.0000 - val_mae: 2509.3108\n",
            "Epoch 111/350\n",
            "3/3 - 0s - loss: 7239834.0000 - mae: 2133.6497 - val_loss: 10692757.0000 - val_mae: 2581.9993\n",
            "Epoch 112/350\n",
            "3/3 - 0s - loss: 7209065.0000 - mae: 2109.2900 - val_loss: 10781245.0000 - val_mae: 2609.4851\n",
            "Epoch 113/350\n",
            "3/3 - 0s - loss: 7218172.0000 - mae: 2100.5398 - val_loss: 10530306.0000 - val_mae: 2529.5830\n",
            "Epoch 114/350\n",
            "3/3 - 0s - loss: 7252572.0000 - mae: 2131.7664 - val_loss: 10464061.0000 - val_mae: 2492.4958\n",
            "Epoch 115/350\n",
            "3/3 - 0s - loss: 7144896.5000 - mae: 2097.6306 - val_loss: 11053361.0000 - val_mae: 2674.7522\n",
            "Epoch 116/350\n",
            "3/3 - 0s - loss: 7466027.0000 - mae: 2123.8926 - val_loss: 10657775.0000 - val_mae: 2586.8953\n",
            "Epoch 117/350\n",
            "3/3 - 0s - loss: 7676592.5000 - mae: 2197.0718 - val_loss: 10438948.0000 - val_mae: 2421.9666\n",
            "Epoch 118/350\n",
            "3/3 - 0s - loss: 7142110.0000 - mae: 2104.8232 - val_loss: 11290381.0000 - val_mae: 2720.5315\n",
            "Epoch 119/350\n",
            "3/3 - 0s - loss: 7250727.5000 - mae: 2092.0256 - val_loss: 10691261.0000 - val_mae: 2605.0720\n",
            "Epoch 120/350\n",
            "3/3 - 0s - loss: 7231555.0000 - mae: 2104.4487 - val_loss: 10420956.0000 - val_mae: 2430.7766\n",
            "Epoch 121/350\n",
            "3/3 - 0s - loss: 7273971.5000 - mae: 2156.1084 - val_loss: 10433539.0000 - val_mae: 2501.4580\n",
            "Epoch 122/350\n",
            "3/3 - 0s - loss: 7463178.0000 - mae: 2154.5156 - val_loss: 11170216.0000 - val_mae: 2706.4463\n",
            "Epoch 123/350\n",
            "3/3 - 0s - loss: 7022939.5000 - mae: 2086.1670 - val_loss: 10432546.0000 - val_mae: 2414.0354\n",
            "Epoch 124/350\n",
            "3/3 - 0s - loss: 7247713.0000 - mae: 2150.3086 - val_loss: 10513588.0000 - val_mae: 2545.7590\n",
            "Epoch 125/350\n",
            "3/3 - 0s - loss: 7078606.0000 - mae: 2084.5859 - val_loss: 11096216.0000 - val_mae: 2697.2693\n",
            "Epoch 126/350\n",
            "3/3 - 0s - loss: 7298354.0000 - mae: 2101.9961 - val_loss: 10430389.0000 - val_mae: 2499.6382\n",
            "Epoch 127/350\n",
            "3/3 - 0s - loss: 7091443.5000 - mae: 2123.9465 - val_loss: 10414345.0000 - val_mae: 2406.7322\n",
            "Epoch 128/350\n",
            "3/3 - 0s - loss: 7463228.5000 - mae: 2143.0212 - val_loss: 11136245.0000 - val_mae: 2707.4226\n",
            "Epoch 129/350\n",
            "3/3 - 0s - loss: 7030992.0000 - mae: 2084.9973 - val_loss: 10408136.0000 - val_mae: 2473.0110\n",
            "Epoch 130/350\n",
            "3/3 - 0s - loss: 7151851.5000 - mae: 2110.1577 - val_loss: 10666505.0000 - val_mae: 2609.7988\n",
            "Epoch 131/350\n",
            "3/3 - 0s - loss: 7129769.0000 - mae: 2115.3733 - val_loss: 10816144.0000 - val_mae: 2648.2280\n",
            "Epoch 132/350\n",
            "3/3 - 0s - loss: 7059343.5000 - mae: 2084.5862 - val_loss: 10622356.0000 - val_mae: 2599.3105\n",
            "Epoch 133/350\n",
            "3/3 - 0s - loss: 7038991.0000 - mae: 2085.0710 - val_loss: 10480785.0000 - val_mae: 2543.3508\n",
            "Epoch 134/350\n",
            "3/3 - 0s - loss: 7245715.0000 - mae: 2115.3518 - val_loss: 10492521.0000 - val_mae: 2548.7920\n",
            "Epoch 135/350\n",
            "3/3 - 0s - loss: 7588659.5000 - mae: 2164.1328 - val_loss: 11136996.0000 - val_mae: 2713.5754\n",
            "Epoch 136/350\n",
            "3/3 - 0s - loss: 7134926.0000 - mae: 2103.6038 - val_loss: 10445520.0000 - val_mae: 2404.3821\n",
            "Epoch 137/350\n",
            "3/3 - 0s - loss: 7241559.0000 - mae: 2132.3528 - val_loss: 12450933.0000 - val_mae: 2721.7708\n",
            "Epoch 138/350\n",
            "3/3 - 0s - loss: 7423517.5000 - mae: 2097.7710 - val_loss: 14416431.0000 - val_mae: 2850.2610\n",
            "Epoch 139/350\n",
            "3/3 - 0s - loss: 7785365.0000 - mae: 2153.8792 - val_loss: 12934031.0000 - val_mae: 2578.4751\n",
            "Epoch 140/350\n",
            "3/3 - 0s - loss: 7713171.5000 - mae: 2079.4011 - val_loss: 13314148.0000 - val_mae: 2788.2405\n",
            "Epoch 141/350\n",
            "3/3 - 0s - loss: 6870507.0000 - mae: 1959.4763 - val_loss: 12651760.0000 - val_mae: 2559.2151\n",
            "Epoch 142/350\n",
            "3/3 - 0s - loss: 7310330.5000 - mae: 2107.0784 - val_loss: 12519715.0000 - val_mae: 2626.6077\n",
            "Epoch 143/350\n",
            "3/3 - 0s - loss: 7548593.0000 - mae: 2086.4597 - val_loss: 13071825.0000 - val_mae: 2833.5671\n",
            "Epoch 144/350\n",
            "3/3 - 0s - loss: 7568529.0000 - mae: 2110.6206 - val_loss: 12920937.0000 - val_mae: 2698.3528\n",
            "Epoch 145/350\n",
            "3/3 - 0s - loss: 7789234.5000 - mae: 2201.8108 - val_loss: 13602089.0000 - val_mae: 2851.5312\n",
            "Epoch 146/350\n",
            "3/3 - 0s - loss: 7486908.5000 - mae: 2117.1741 - val_loss: 14125765.0000 - val_mae: 2947.6023\n",
            "Epoch 147/350\n",
            "3/3 - 0s - loss: 7387374.5000 - mae: 2101.7078 - val_loss: 14907900.0000 - val_mae: 2947.5879\n",
            "Epoch 148/350\n",
            "3/3 - 0s - loss: 7236533.5000 - mae: 2084.9980 - val_loss: 14601115.0000 - val_mae: 2856.6238\n",
            "Epoch 149/350\n",
            "3/3 - 0s - loss: 7451238.5000 - mae: 2138.9846 - val_loss: 14523693.0000 - val_mae: 2963.1482\n",
            "Epoch 150/350\n",
            "3/3 - 0s - loss: 7619556.0000 - mae: 2121.4360 - val_loss: 14634003.0000 - val_mae: 3017.5774\n",
            "Epoch 151/350\n",
            "3/3 - 0s - loss: 8011452.5000 - mae: 2210.2688 - val_loss: 13568596.0000 - val_mae: 2632.4485\n",
            "Epoch 152/350\n",
            "3/3 - 0s - loss: 7864112.0000 - mae: 2211.5703 - val_loss: 15708065.0000 - val_mae: 3141.5625\n",
            "Epoch 153/350\n",
            "3/3 - 0s - loss: 7515898.5000 - mae: 2114.0139 - val_loss: 13619213.0000 - val_mae: 2681.0894\n",
            "Epoch 154/350\n",
            "3/3 - 0s - loss: 8025919.5000 - mae: 2246.4839 - val_loss: 13539420.0000 - val_mae: 2846.2957\n",
            "Epoch 155/350\n",
            "3/3 - 0s - loss: 7774018.0000 - mae: 2132.8955 - val_loss: 14369619.0000 - val_mae: 3010.1697\n",
            "Epoch 156/350\n",
            "3/3 - 0s - loss: 7089031.0000 - mae: 2099.0144 - val_loss: 14139221.0000 - val_mae: 2836.9036\n",
            "Epoch 157/350\n",
            "3/3 - 0s - loss: 7949675.5000 - mae: 2275.2798 - val_loss: 13411908.0000 - val_mae: 2853.6472\n",
            "Epoch 158/350\n",
            "3/3 - 0s - loss: 7322020.5000 - mae: 2092.5798 - val_loss: 12962843.0000 - val_mae: 2783.8196\n",
            "Epoch 159/350\n",
            "3/3 - 0s - loss: 6876547.5000 - mae: 2041.1266 - val_loss: 15015399.0000 - val_mae: 2854.7668\n",
            "Epoch 160/350\n",
            "3/3 - 0s - loss: 6858167.0000 - mae: 2088.8782 - val_loss: 12201016.0000 - val_mae: 2721.8750\n",
            "Epoch 161/350\n",
            "3/3 - 0s - loss: 6994108.0000 - mae: 2048.4487 - val_loss: 12045239.0000 - val_mae: 2709.1106\n",
            "Epoch 162/350\n",
            "3/3 - 0s - loss: 7332862.5000 - mae: 2130.3706 - val_loss: 11760307.0000 - val_mae: 2648.0637\n",
            "Epoch 163/350\n",
            "3/3 - 0s - loss: 7528363.5000 - mae: 2154.0720 - val_loss: 11980461.0000 - val_mae: 2700.5535\n",
            "Epoch 164/350\n",
            "3/3 - 0s - loss: 7240894.0000 - mae: 2094.7988 - val_loss: 11961167.0000 - val_mae: 2666.7434\n",
            "Epoch 165/350\n",
            "3/3 - 0s - loss: 7500586.0000 - mae: 2135.5110 - val_loss: 12047765.0000 - val_mae: 2675.7517\n",
            "Epoch 166/350\n",
            "3/3 - 0s - loss: 7650828.5000 - mae: 2213.4529 - val_loss: 12218607.0000 - val_mae: 2685.4241\n",
            "Epoch 167/350\n",
            "3/3 - 0s - loss: 8082797.0000 - mae: 2189.9658 - val_loss: 12789771.0000 - val_mae: 2781.2615\n",
            "Epoch 168/350\n",
            "3/3 - 0s - loss: 7338992.0000 - mae: 2144.8298 - val_loss: 12910919.0000 - val_mae: 2805.0056\n",
            "Epoch 169/350\n",
            "3/3 - 0s - loss: 7776926.0000 - mae: 2195.5869 - val_loss: 13107352.0000 - val_mae: 2819.4795\n",
            "Epoch 170/350\n",
            "3/3 - 0s - loss: 7079328.5000 - mae: 2046.0292 - val_loss: 12599373.0000 - val_mae: 2753.5750\n",
            "Epoch 171/350\n",
            "3/3 - 0s - loss: 7132442.5000 - mae: 2118.5828 - val_loss: 12380947.0000 - val_mae: 2728.8450\n",
            "Epoch 172/350\n",
            "3/3 - 0s - loss: 7175813.5000 - mae: 2057.9761 - val_loss: 12681880.0000 - val_mae: 2763.8213\n",
            "Epoch 173/350\n",
            "3/3 - 0s - loss: 6679177.0000 - mae: 1994.4705 - val_loss: 12701093.0000 - val_mae: 2747.6667\n",
            "Epoch 174/350\n",
            "3/3 - 0s - loss: 7112165.5000 - mae: 2103.4480 - val_loss: 12494356.0000 - val_mae: 2738.7590\n",
            "Epoch 175/350\n",
            "3/3 - 0s - loss: 7116094.0000 - mae: 2036.1165 - val_loss: 13452856.0000 - val_mae: 2895.5850\n",
            "Epoch 176/350\n",
            "3/3 - 0s - loss: 7411270.5000 - mae: 2147.1143 - val_loss: 13207836.0000 - val_mae: 2871.4788\n",
            "Epoch 177/350\n",
            "3/3 - 0s - loss: 6909660.0000 - mae: 2111.2532 - val_loss: 15705528.0000 - val_mae: 3101.6912\n",
            "Epoch 178/350\n",
            "3/3 - 0s - loss: 7537735.0000 - mae: 2111.5220 - val_loss: 13582368.0000 - val_mae: 2925.0735\n",
            "Epoch 179/350\n",
            "3/3 - 0s - loss: 7782295.0000 - mae: 2275.8181 - val_loss: 12083083.0000 - val_mae: 2726.6819\n",
            "Epoch 180/350\n",
            "3/3 - 0s - loss: 7349474.5000 - mae: 2094.6687 - val_loss: 14964995.0000 - val_mae: 2933.2520\n",
            "Epoch 181/350\n",
            "3/3 - 0s - loss: 7924040.5000 - mae: 2204.7556 - val_loss: 12793835.0000 - val_mae: 2710.4238\n",
            "Epoch 182/350\n",
            "3/3 - 0s - loss: 7791998.5000 - mae: 2182.2900 - val_loss: 12190877.0000 - val_mae: 2797.3752\n",
            "Epoch 183/350\n",
            "3/3 - 0s - loss: 8332015.0000 - mae: 2224.8230 - val_loss: 13564160.0000 - val_mae: 3033.6389\n",
            "Epoch 184/350\n",
            "3/3 - 0s - loss: 7229998.5000 - mae: 2040.4651 - val_loss: 13409793.0000 - val_mae: 2809.0732\n",
            "Epoch 185/350\n",
            "3/3 - 0s - loss: 8174187.0000 - mae: 2280.8674 - val_loss: 12396321.0000 - val_mae: 2782.8997\n",
            "Epoch 186/350\n",
            "3/3 - 0s - loss: 7986821.5000 - mae: 2165.3315 - val_loss: 13482507.0000 - val_mae: 3025.4084\n",
            "Epoch 187/350\n",
            "3/3 - 0s - loss: 7559145.5000 - mae: 2078.6392 - val_loss: 12762869.0000 - val_mae: 2758.0505\n",
            "Epoch 188/350\n",
            "3/3 - 0s - loss: 7745035.5000 - mae: 2197.8750 - val_loss: 12449500.0000 - val_mae: 2846.1875\n",
            "Epoch 189/350\n",
            "3/3 - 0s - loss: 7965477.5000 - mae: 2167.1648 - val_loss: 12429392.0000 - val_mae: 2849.7930\n",
            "Epoch 190/350\n",
            "3/3 - 0s - loss: 8008406.5000 - mae: 2192.1716 - val_loss: 12537963.0000 - val_mae: 2732.9417\n",
            "Epoch 191/350\n",
            "3/3 - 0s - loss: 7418484.0000 - mae: 2080.1670 - val_loss: 13312843.0000 - val_mae: 3040.3098\n",
            "Epoch 192/350\n",
            "3/3 - 0s - loss: 7643108.0000 - mae: 2107.5718 - val_loss: 12292336.0000 - val_mae: 2790.2493\n",
            "Epoch 193/350\n",
            "3/3 - 0s - loss: 7352448.0000 - mae: 2123.4910 - val_loss: 12689405.0000 - val_mae: 2746.6824\n",
            "Epoch 194/350\n",
            "3/3 - 0s - loss: 7472056.5000 - mae: 2155.9609 - val_loss: 12762387.0000 - val_mae: 2947.7275\n",
            "Epoch 195/350\n",
            "3/3 - 0s - loss: 7823064.0000 - mae: 2150.2673 - val_loss: 12519957.0000 - val_mae: 2891.3523\n",
            "Epoch 196/350\n",
            "3/3 - 0s - loss: 8160306.5000 - mae: 2243.9714 - val_loss: 12707132.0000 - val_mae: 2746.7883\n",
            "Epoch 197/350\n",
            "3/3 - 0s - loss: 7813109.5000 - mae: 2205.8442 - val_loss: 13464685.0000 - val_mae: 3054.5781\n",
            "Epoch 198/350\n",
            "3/3 - 0s - loss: 7442489.5000 - mae: 2083.0889 - val_loss: 12207843.0000 - val_mae: 2715.6638\n",
            "Epoch 199/350\n",
            "3/3 - 0s - loss: 7550102.5000 - mae: 2170.4766 - val_loss: 12359888.0000 - val_mae: 2691.4104\n",
            "Epoch 200/350\n",
            "3/3 - 0s - loss: 7798770.0000 - mae: 2224.9326 - val_loss: 13242825.0000 - val_mae: 3024.9382\n",
            "Epoch 201/350\n",
            "3/3 - 0s - loss: 7458244.0000 - mae: 2070.1428 - val_loss: 12360051.0000 - val_mae: 2687.7693\n",
            "Epoch 202/350\n",
            "3/3 - 0s - loss: 7423848.0000 - mae: 2144.2214 - val_loss: 12204487.0000 - val_mae: 2704.8613\n",
            "Epoch 203/350\n",
            "3/3 - 0s - loss: 7688661.0000 - mae: 2131.9465 - val_loss: 12651219.0000 - val_mae: 2929.9915\n",
            "Epoch 204/350\n",
            "3/3 - 0s - loss: 7428560.0000 - mae: 2082.1404 - val_loss: 12165945.0000 - val_mae: 2708.9641\n",
            "Epoch 205/350\n",
            "3/3 - 0s - loss: 7373828.0000 - mae: 2114.3042 - val_loss: 12389304.0000 - val_mae: 2872.7224\n",
            "Epoch 206/350\n",
            "3/3 - 0s - loss: 7125907.5000 - mae: 2051.0339 - val_loss: 12105832.0000 - val_mae: 2723.4607\n",
            "Epoch 207/350\n",
            "3/3 - 0s - loss: 7116882.5000 - mae: 2061.9507 - val_loss: 12100608.0000 - val_mae: 2741.6394\n",
            "Epoch 208/350\n",
            "3/3 - 0s - loss: 7097554.5000 - mae: 2057.5896 - val_loss: 12161285.0000 - val_mae: 2798.5996\n",
            "Epoch 209/350\n",
            "3/3 - 0s - loss: 7130778.5000 - mae: 2060.4080 - val_loss: 12097953.0000 - val_mae: 2754.2119\n",
            "Epoch 210/350\n",
            "3/3 - 0s - loss: 7161863.0000 - mae: 2030.1110 - val_loss: 12222569.0000 - val_mae: 2830.8879\n",
            "Epoch 211/350\n",
            "3/3 - 0s - loss: 7003271.5000 - mae: 2031.4502 - val_loss: 12134397.0000 - val_mae: 2706.6343\n",
            "Epoch 212/350\n",
            "3/3 - 0s - loss: 7116340.5000 - mae: 2080.7192 - val_loss: 12081113.0000 - val_mae: 2717.0374\n",
            "Epoch 213/350\n",
            "3/3 - 0s - loss: 7015338.0000 - mae: 2049.9797 - val_loss: 12402112.0000 - val_mae: 2891.3513\n",
            "Epoch 214/350\n",
            "3/3 - 0s - loss: 7325428.5000 - mae: 2062.9250 - val_loss: 12161348.0000 - val_mae: 2816.2734\n",
            "Epoch 215/350\n",
            "3/3 - 0s - loss: 6958403.0000 - mae: 2044.5679 - val_loss: 12213548.0000 - val_mae: 2691.3972\n",
            "Epoch 216/350\n",
            "3/3 - 0s - loss: 7080124.0000 - mae: 2074.4302 - val_loss: 12142131.0000 - val_mae: 2812.6907\n",
            "Epoch 217/350\n",
            "3/3 - 0s - loss: 7029865.0000 - mae: 2013.6857 - val_loss: 12505456.0000 - val_mae: 2921.8611\n",
            "Epoch 218/350\n",
            "3/3 - 0s - loss: 7672541.0000 - mae: 2143.9011 - val_loss: 12099784.0000 - val_mae: 2702.1482\n",
            "Epoch 219/350\n",
            "3/3 - 0s - loss: 7013269.0000 - mae: 2043.8870 - val_loss: 12773948.0000 - val_mae: 2985.3591\n",
            "Epoch 220/350\n",
            "3/3 - 0s - loss: 7140701.5000 - mae: 2037.8700 - val_loss: 11940347.0000 - val_mae: 2701.2136\n",
            "Epoch 221/350\n",
            "3/3 - 0s - loss: 7137926.5000 - mae: 2099.6663 - val_loss: 11997699.0000 - val_mae: 2708.6709\n",
            "Epoch 222/350\n",
            "3/3 - 0s - loss: 6980423.5000 - mae: 2027.6144 - val_loss: 12418007.0000 - val_mae: 2912.8718\n",
            "Epoch 223/350\n",
            "3/3 - 0s - loss: 6992828.0000 - mae: 2014.0922 - val_loss: 12047976.0000 - val_mae: 2744.5378\n",
            "Epoch 224/350\n",
            "3/3 - 0s - loss: 6886045.5000 - mae: 2026.1483 - val_loss: 12094813.0000 - val_mae: 2712.5146\n",
            "Epoch 225/350\n",
            "3/3 - 0s - loss: 7110902.0000 - mae: 2079.6113 - val_loss: 12085072.0000 - val_mae: 2798.4973\n",
            "Epoch 226/350\n",
            "3/3 - 0s - loss: 7249586.0000 - mae: 2050.9529 - val_loss: 12352793.0000 - val_mae: 2901.7190\n",
            "Epoch 227/350\n",
            "3/3 - 0s - loss: 6806383.0000 - mae: 2007.4032 - val_loss: 12249077.0000 - val_mae: 2704.1462\n",
            "Epoch 228/350\n",
            "3/3 - 0s - loss: 7132535.5000 - mae: 2101.1252 - val_loss: 12020920.0000 - val_mae: 2770.0813\n",
            "Epoch 229/350\n",
            "3/3 - 0s - loss: 6825057.0000 - mae: 2006.4775 - val_loss: 12535208.0000 - val_mae: 2954.2771\n",
            "Epoch 230/350\n",
            "3/3 - 0s - loss: 7051327.5000 - mae: 2024.8560 - val_loss: 11995636.0000 - val_mae: 2719.4741\n",
            "Epoch 231/350\n",
            "3/3 - 0s - loss: 7260547.0000 - mae: 2106.9758 - val_loss: 12073043.0000 - val_mae: 2700.4016\n",
            "Epoch 232/350\n",
            "3/3 - 0s - loss: 7295887.5000 - mae: 2051.7412 - val_loss: 12829072.0000 - val_mae: 3010.6428\n",
            "Epoch 233/350\n",
            "3/3 - 0s - loss: 6904135.5000 - mae: 1996.9591 - val_loss: 12378893.0000 - val_mae: 2727.8926\n",
            "Epoch 234/350\n",
            "3/3 - 0s - loss: 7116975.0000 - mae: 2107.2366 - val_loss: 11997031.0000 - val_mae: 2733.8162\n",
            "Epoch 235/350\n",
            "3/3 - 0s - loss: 6952728.5000 - mae: 2027.3922 - val_loss: 12278584.0000 - val_mae: 2901.5012\n",
            "Epoch 236/350\n",
            "3/3 - 0s - loss: 6886467.5000 - mae: 2008.8716 - val_loss: 12053624.0000 - val_mae: 2719.6687\n",
            "Epoch 237/350\n",
            "3/3 - 0s - loss: 6824350.0000 - mae: 2021.9674 - val_loss: 12021509.0000 - val_mae: 2794.4270\n",
            "Epoch 238/350\n",
            "3/3 - 0s - loss: 6875063.0000 - mae: 2027.7910 - val_loss: 12030755.0000 - val_mae: 2808.3621\n",
            "Epoch 239/350\n",
            "3/3 - 0s - loss: 6955029.0000 - mae: 2017.1494 - val_loss: 12030877.0000 - val_mae: 2816.0461\n",
            "Epoch 240/350\n",
            "3/3 - 0s - loss: 6783325.0000 - mae: 1995.0117 - val_loss: 12003243.0000 - val_mae: 2727.7161\n",
            "Epoch 241/350\n",
            "3/3 - 0s - loss: 6889842.0000 - mae: 2012.7991 - val_loss: 11989581.0000 - val_mae: 2724.7444\n",
            "Epoch 242/350\n",
            "3/3 - 0s - loss: 6795454.0000 - mae: 2014.2524 - val_loss: 11976876.0000 - val_mae: 2726.2966\n",
            "Epoch 243/350\n",
            "3/3 - 0s - loss: 6856618.0000 - mae: 2007.7191 - val_loss: 12085041.0000 - val_mae: 2849.5293\n",
            "Epoch 244/350\n",
            "3/3 - 0s - loss: 7010907.5000 - mae: 2034.2206 - val_loss: 12063624.0000 - val_mae: 2708.4319\n",
            "Epoch 245/350\n",
            "3/3 - 0s - loss: 7050473.5000 - mae: 2052.8560 - val_loss: 12297947.0000 - val_mae: 2915.5498\n",
            "Epoch 246/350\n",
            "3/3 - 0s - loss: 6874470.5000 - mae: 2007.2212 - val_loss: 11982632.0000 - val_mae: 2715.5261\n",
            "Epoch 247/350\n",
            "3/3 - 0s - loss: 6784046.5000 - mae: 2018.2909 - val_loss: 11995663.0000 - val_mae: 2717.2148\n",
            "Epoch 248/350\n",
            "3/3 - 0s - loss: 6778717.0000 - mae: 2020.9646 - val_loss: 11996109.0000 - val_mae: 2806.5911\n",
            "Epoch 249/350\n",
            "3/3 - 0s - loss: 6790207.5000 - mae: 1988.1764 - val_loss: 12032572.0000 - val_mae: 2829.3962\n",
            "Epoch 250/350\n",
            "3/3 - 0s - loss: 6726981.0000 - mae: 1997.0641 - val_loss: 12086861.0000 - val_mae: 2704.6667\n",
            "Epoch 251/350\n",
            "3/3 - 0s - loss: 6874544.0000 - mae: 2045.3882 - val_loss: 11923175.0000 - val_mae: 2734.4543\n",
            "Epoch 252/350\n",
            "3/3 - 0s - loss: 6739179.0000 - mae: 1996.1190 - val_loss: 11928063.0000 - val_mae: 2739.9612\n",
            "Epoch 253/350\n",
            "3/3 - 0s - loss: 6732762.0000 - mae: 2009.2678 - val_loss: 11957436.0000 - val_mae: 2722.7559\n",
            "Epoch 254/350\n",
            "3/3 - 0s - loss: 6735362.0000 - mae: 2006.4272 - val_loss: 11937901.0000 - val_mae: 2753.3740\n",
            "Epoch 255/350\n",
            "3/3 - 0s - loss: 6764616.5000 - mae: 1984.9091 - val_loss: 11946632.0000 - val_mae: 2801.0715\n",
            "Epoch 256/350\n",
            "3/3 - 0s - loss: 6744708.0000 - mae: 1992.7383 - val_loss: 11996739.0000 - val_mae: 2708.1169\n",
            "Epoch 257/350\n",
            "3/3 - 0s - loss: 6793377.0000 - mae: 2026.5248 - val_loss: 11916785.0000 - val_mae: 2790.8425\n",
            "Epoch 258/350\n",
            "3/3 - 0s - loss: 6770438.5000 - mae: 2003.1350 - val_loss: 11911473.0000 - val_mae: 2737.2346\n",
            "Epoch 259/350\n",
            "3/3 - 0s - loss: 6672404.5000 - mae: 1993.1665 - val_loss: 11959784.0000 - val_mae: 2712.2322\n",
            "Epoch 260/350\n",
            "3/3 - 0s - loss: 6714544.0000 - mae: 2005.2758 - val_loss: 11911331.0000 - val_mae: 2788.0671\n",
            "Epoch 261/350\n",
            "3/3 - 0s - loss: 6820416.0000 - mae: 2004.7788 - val_loss: 11936392.0000 - val_mae: 2818.2188\n",
            "Epoch 262/350\n",
            "3/3 - 0s - loss: 7526414.0000 - mae: 2158.8318 - val_loss: 11983213.0000 - val_mae: 2713.7874\n",
            "Epoch 263/350\n",
            "3/3 - 0s - loss: 6909929.5000 - mae: 2041.0736 - val_loss: 12483379.0000 - val_mae: 2971.5234\n",
            "Epoch 264/350\n",
            "3/3 - 0s - loss: 6926324.5000 - mae: 2048.6191 - val_loss: 12358984.0000 - val_mae: 2734.5654\n",
            "Epoch 265/350\n",
            "3/3 - 0s - loss: 6878182.0000 - mae: 2050.2278 - val_loss: 11952265.0000 - val_mae: 2816.7998\n",
            "Epoch 266/350\n",
            "3/3 - 0s - loss: 6821904.0000 - mae: 2005.4708 - val_loss: 12139719.0000 - val_mae: 2890.0330\n",
            "Epoch 267/350\n",
            "3/3 - 0s - loss: 6827938.0000 - mae: 2029.4856 - val_loss: 12112952.0000 - val_mae: 2707.5061\n",
            "Epoch 268/350\n",
            "3/3 - 0s - loss: 6799252.5000 - mae: 2025.5950 - val_loss: 11894055.0000 - val_mae: 2728.4187\n",
            "Epoch 269/350\n",
            "3/3 - 0s - loss: 6960497.0000 - mae: 2057.9309 - val_loss: 11907876.0000 - val_mae: 2796.6409\n",
            "Epoch 270/350\n",
            "3/3 - 0s - loss: 7002244.0000 - mae: 2023.3888 - val_loss: 12115163.0000 - val_mae: 2894.0911\n",
            "Epoch 271/350\n",
            "3/3 - 0s - loss: 6788531.5000 - mae: 2030.2936 - val_loss: 12319989.0000 - val_mae: 2730.7859\n",
            "Epoch 272/350\n",
            "3/3 - 0s - loss: 7016744.0000 - mae: 2092.7102 - val_loss: 12078824.0000 - val_mae: 2875.3665\n",
            "Epoch 273/350\n",
            "3/3 - 0s - loss: 6808497.0000 - mae: 1990.7877 - val_loss: 11963963.0000 - val_mae: 2720.2842\n",
            "Epoch 274/350\n",
            "3/3 - 0s - loss: 6764877.5000 - mae: 2019.9232 - val_loss: 11936424.0000 - val_mae: 2810.0593\n",
            "Epoch 275/350\n",
            "3/3 - 0s - loss: 7082807.5000 - mae: 2032.1335 - val_loss: 12050045.0000 - val_mae: 2949.4160\n",
            "Epoch 276/350\n",
            "3/3 - 0s - loss: 7158328.5000 - mae: 2109.6577 - val_loss: 11227503.0000 - val_mae: 2588.0403\n",
            "Epoch 277/350\n",
            "3/3 - 0s - loss: 7283608.0000 - mae: 2132.9998 - val_loss: 12870899.0000 - val_mae: 2968.7383\n",
            "Epoch 278/350\n",
            "3/3 - 0s - loss: 7729321.5000 - mae: 2132.9126 - val_loss: 12838040.0000 - val_mae: 2924.9160\n",
            "Epoch 279/350\n",
            "3/3 - 0s - loss: 7662385.0000 - mae: 2188.1802 - val_loss: 12780105.0000 - val_mae: 2744.5723\n",
            "Epoch 280/350\n",
            "3/3 - 0s - loss: 7135395.0000 - mae: 2094.6201 - val_loss: 13244219.0000 - val_mae: 3138.2629\n",
            "Epoch 281/350\n",
            "3/3 - 0s - loss: 7314923.5000 - mae: 2080.6917 - val_loss: 12946256.0000 - val_mae: 2889.1973\n",
            "Epoch 282/350\n",
            "3/3 - 0s - loss: 7181872.0000 - mae: 2095.4355 - val_loss: 12875291.0000 - val_mae: 2933.9363\n",
            "Epoch 283/350\n",
            "3/3 - 0s - loss: 7192986.0000 - mae: 2081.5649 - val_loss: 12952729.0000 - val_mae: 2991.7529\n",
            "Epoch 284/350\n",
            "3/3 - 0s - loss: 7224411.5000 - mae: 2094.0593 - val_loss: 12952145.0000 - val_mae: 2908.2976\n",
            "Epoch 285/350\n",
            "3/3 - 0s - loss: 7567638.0000 - mae: 2169.7795 - val_loss: 12885451.0000 - val_mae: 2960.3254\n",
            "Epoch 286/350\n",
            "3/3 - 0s - loss: 7593698.5000 - mae: 2142.2678 - val_loss: 12805129.0000 - val_mae: 2926.3821\n",
            "Epoch 287/350\n",
            "3/3 - 0s - loss: 7283515.0000 - mae: 2130.0693 - val_loss: 12948672.0000 - val_mae: 2815.1523\n",
            "Epoch 288/350\n",
            "3/3 - 0s - loss: 7488473.5000 - mae: 2168.8259 - val_loss: 13245843.0000 - val_mae: 3091.8770\n",
            "Epoch 289/350\n",
            "3/3 - 0s - loss: 7325029.5000 - mae: 2132.3660 - val_loss: 13233233.0000 - val_mae: 2795.4900\n",
            "Epoch 290/350\n",
            "3/3 - 0s - loss: 7304509.0000 - mae: 2101.3560 - val_loss: 13199717.0000 - val_mae: 3066.3962\n",
            "Epoch 291/350\n",
            "3/3 - 0s - loss: 7142867.0000 - mae: 2064.9104 - val_loss: 12648221.0000 - val_mae: 2900.4446\n",
            "Epoch 292/350\n",
            "3/3 - 0s - loss: 6916416.5000 - mae: 2063.1797 - val_loss: 12634227.0000 - val_mae: 2895.7812\n",
            "Epoch 293/350\n",
            "3/3 - 0s - loss: 7066011.5000 - mae: 2049.3389 - val_loss: 12665567.0000 - val_mae: 2918.5632\n",
            "Epoch 294/350\n",
            "3/3 - 0s - loss: 6916311.0000 - mae: 2060.2659 - val_loss: 12675677.0000 - val_mae: 2822.6106\n",
            "Epoch 295/350\n",
            "3/3 - 0s - loss: 7348126.0000 - mae: 2102.5750 - val_loss: 12642125.0000 - val_mae: 2829.7949\n",
            "Epoch 296/350\n",
            "3/3 - 0s - loss: 7004383.0000 - mae: 2077.4956 - val_loss: 12620917.0000 - val_mae: 2827.7170\n",
            "Epoch 297/350\n",
            "3/3 - 0s - loss: 7049399.0000 - mae: 2065.2871 - val_loss: 12534437.0000 - val_mae: 2963.7090\n",
            "Epoch 298/350\n",
            "3/3 - 0s - loss: 7089287.5000 - mae: 2040.1173 - val_loss: 12798731.0000 - val_mae: 2772.4023\n",
            "Epoch 299/350\n",
            "3/3 - 0s - loss: 7024737.0000 - mae: 2091.7791 - val_loss: 12670352.0000 - val_mae: 2953.2551\n",
            "Epoch 300/350\n",
            "3/3 - 0s - loss: 7150277.5000 - mae: 2067.9099 - val_loss: 11606593.0000 - val_mae: 2782.8838\n",
            "Epoch 301/350\n",
            "3/3 - 0s - loss: 7250498.0000 - mae: 2106.7998 - val_loss: 11848541.0000 - val_mae: 2683.9011\n",
            "Epoch 302/350\n",
            "3/3 - 0s - loss: 6558474.5000 - mae: 1971.7708 - val_loss: 12760957.0000 - val_mae: 3000.7366\n",
            "Epoch 303/350\n",
            "3/3 - 0s - loss: 7011765.5000 - mae: 2049.7949 - val_loss: 12205357.0000 - val_mae: 2757.1575\n",
            "Epoch 304/350\n",
            "3/3 - 0s - loss: 6974337.5000 - mae: 2071.9729 - val_loss: 12409328.0000 - val_mae: 2756.1980\n",
            "Epoch 305/350\n",
            "3/3 - 0s - loss: 6538889.0000 - mae: 1967.8386 - val_loss: 12874941.0000 - val_mae: 3069.0723\n",
            "Epoch 306/350\n",
            "3/3 - 0s - loss: 7155436.5000 - mae: 2059.3894 - val_loss: 12361539.0000 - val_mae: 2784.1543\n",
            "Epoch 307/350\n",
            "3/3 - 0s - loss: 7598211.0000 - mae: 2190.8132 - val_loss: 12574141.0000 - val_mae: 2766.2454\n",
            "Epoch 308/350\n",
            "3/3 - 0s - loss: 7954473.0000 - mae: 2175.7556 - val_loss: 13127669.0000 - val_mae: 3114.9082\n",
            "Epoch 309/350\n",
            "3/3 - 0s - loss: 7322589.5000 - mae: 2119.3901 - val_loss: 13190485.0000 - val_mae: 2789.8489\n",
            "Epoch 310/350\n",
            "3/3 - 0s - loss: 6845451.5000 - mae: 2073.4341 - val_loss: 12906459.0000 - val_mae: 3060.3665\n",
            "Epoch 311/350\n",
            "3/3 - 0s - loss: 7014265.0000 - mae: 2034.2316 - val_loss: 12141931.0000 - val_mae: 2814.1777\n",
            "Epoch 312/350\n",
            "3/3 - 0s - loss: 6624190.0000 - mae: 1979.4078 - val_loss: 12460531.0000 - val_mae: 2705.4309\n",
            "Epoch 313/350\n",
            "3/3 - 0s - loss: 6774660.0000 - mae: 2022.9911 - val_loss: 12128667.0000 - val_mae: 2842.2581\n",
            "Epoch 314/350\n",
            "3/3 - 0s - loss: 6693314.0000 - mae: 1999.6990 - val_loss: 12138321.0000 - val_mae: 2845.7214\n",
            "Epoch 315/350\n",
            "3/3 - 0s - loss: 6662487.0000 - mae: 1995.3492 - val_loss: 12338724.0000 - val_mae: 2702.8318\n",
            "Epoch 316/350\n",
            "3/3 - 0s - loss: 6746665.5000 - mae: 2024.7655 - val_loss: 12090971.0000 - val_mae: 2778.1934\n",
            "Epoch 317/350\n",
            "3/3 - 0s - loss: 6667212.0000 - mae: 2002.5884 - val_loss: 12213093.0000 - val_mae: 2878.8660\n",
            "Epoch 318/350\n",
            "3/3 - 0s - loss: 6831543.0000 - mae: 2011.6703 - val_loss: 12147841.0000 - val_mae: 2727.4036\n",
            "Epoch 319/350\n",
            "3/3 - 0s - loss: 6578397.0000 - mae: 1997.7871 - val_loss: 12163696.0000 - val_mae: 2862.5225\n",
            "Epoch 320/350\n",
            "3/3 - 0s - loss: 6882784.5000 - mae: 2013.9200 - val_loss: 12067856.0000 - val_mae: 2793.7898\n",
            "Epoch 321/350\n",
            "3/3 - 0s - loss: 7725249.5000 - mae: 2195.6289 - val_loss: 12268232.0000 - val_mae: 2691.1177\n",
            "Epoch 322/350\n",
            "3/3 - 0s - loss: 6862875.5000 - mae: 2019.0780 - val_loss: 13256771.0000 - val_mae: 3080.8496\n",
            "Epoch 323/350\n",
            "3/3 - 0s - loss: 6890347.0000 - mae: 2048.0466 - val_loss: 12841231.0000 - val_mae: 2750.7305\n",
            "Epoch 324/350\n",
            "3/3 - 0s - loss: 6901061.0000 - mae: 2066.7029 - val_loss: 12073291.0000 - val_mae: 2773.2715\n",
            "Epoch 325/350\n",
            "3/3 - 0s - loss: 6574894.5000 - mae: 1998.8041 - val_loss: 12109043.0000 - val_mae: 2814.4861\n",
            "Epoch 326/350\n",
            "3/3 - 0s - loss: 6707994.5000 - mae: 1992.8760 - val_loss: 12096231.0000 - val_mae: 2773.3516\n",
            "Epoch 327/350\n",
            "3/3 - 0s - loss: 6548047.0000 - mae: 1982.0874 - val_loss: 12162935.0000 - val_mae: 2718.6321\n",
            "Epoch 328/350\n",
            "3/3 - 0s - loss: 6627909.5000 - mae: 2003.8922 - val_loss: 12099907.0000 - val_mae: 2748.3445\n",
            "Epoch 329/350\n",
            "3/3 - 0s - loss: 6544754.0000 - mae: 1982.4927 - val_loss: 12086876.0000 - val_mae: 2785.4436\n",
            "Epoch 330/350\n",
            "3/3 - 0s - loss: 6651742.0000 - mae: 2020.9485 - val_loss: 12066445.0000 - val_mae: 2749.9316\n",
            "Epoch 331/350\n",
            "3/3 - 0s - loss: 6489646.5000 - mae: 1973.7302 - val_loss: 12177267.0000 - val_mae: 2849.9363\n",
            "Epoch 332/350\n",
            "3/3 - 0s - loss: 6582995.0000 - mae: 1990.2479 - val_loss: 12083864.0000 - val_mae: 2754.2256\n",
            "Epoch 333/350\n",
            "3/3 - 0s - loss: 6551282.0000 - mae: 1974.3872 - val_loss: 12153063.0000 - val_mae: 2718.5615\n",
            "Epoch 334/350\n",
            "3/3 - 0s - loss: 6561979.0000 - mae: 1999.3236 - val_loss: 12102727.0000 - val_mae: 2746.4675\n",
            "Epoch 335/350\n",
            "3/3 - 0s - loss: 6486464.0000 - mae: 1980.4941 - val_loss: 12141203.0000 - val_mae: 2821.7805\n",
            "Epoch 336/350\n",
            "3/3 - 0s - loss: 6551101.0000 - mae: 1973.8398 - val_loss: 12110535.0000 - val_mae: 2759.3269\n",
            "Epoch 337/350\n",
            "3/3 - 0s - loss: 6617720.5000 - mae: 2004.9185 - val_loss: 12258040.0000 - val_mae: 2708.1318\n",
            "Epoch 338/350\n",
            "3/3 - 0s - loss: 6444184.0000 - mae: 1977.4327 - val_loss: 12350987.0000 - val_mae: 2903.7832\n",
            "Epoch 339/350\n",
            "3/3 - 0s - loss: 7052143.0000 - mae: 2044.2675 - val_loss: 12194969.0000 - val_mae: 2716.9397\n",
            "Epoch 340/350\n",
            "3/3 - 0s - loss: 7116767.0000 - mae: 2112.2578 - val_loss: 12584264.0000 - val_mae: 2708.8643\n",
            "Epoch 341/350\n",
            "3/3 - 0s - loss: 6410925.5000 - mae: 1974.3722 - val_loss: 12696608.0000 - val_mae: 2982.5820\n",
            "Epoch 342/350\n",
            "3/3 - 0s - loss: 7009332.5000 - mae: 2040.6257 - val_loss: 12172488.0000 - val_mae: 2719.5422\n",
            "Epoch 343/350\n",
            "3/3 - 0s - loss: 6857370.5000 - mae: 2082.0078 - val_loss: 12477317.0000 - val_mae: 2705.1912\n",
            "Epoch 344/350\n",
            "3/3 - 0s - loss: 6616189.0000 - mae: 2008.3428 - val_loss: 12201449.0000 - val_mae: 2868.8772\n",
            "Epoch 345/350\n",
            "3/3 - 0s - loss: 6614256.5000 - mae: 1975.1724 - val_loss: 12075427.0000 - val_mae: 2746.8274\n",
            "Epoch 346/350\n",
            "3/3 - 0s - loss: 6826022.5000 - mae: 2049.3706 - val_loss: 12357195.0000 - val_mae: 2702.0637\n",
            "Epoch 347/350\n",
            "3/3 - 0s - loss: 6687870.5000 - mae: 1972.8882 - val_loss: 12719699.0000 - val_mae: 2992.7312\n",
            "Epoch 348/350\n",
            "3/3 - 0s - loss: 6863177.0000 - mae: 2036.9025 - val_loss: 12575443.0000 - val_mae: 2720.4741\n",
            "Epoch 349/350\n",
            "3/3 - 0s - loss: 6502597.0000 - mae: 1978.6216 - val_loss: 12418596.0000 - val_mae: 2961.6042\n",
            "Epoch 350/350\n",
            "3/3 - 0s - loss: 6854491.5000 - mae: 2041.6140 - val_loss: 12357601.0000 - val_mae: 2858.0935\n",
            "MSE: 12357601.000, RMSE: 3515.338, MAE: 2858.094\n",
            "Predicted: 16882.143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JVGssrIyTyJ"
      },
      "source": [
        "# result from the first run MSE: 10895209.000, RMSE: 3300.789, MAE: 2576.508\r\n",
        "# Predicted: 17387.074\r\n",
        "\r\n",
        "# result from the second run MSE:12357601.000, RMSE:3515.338, MAE: 2858.094\r\n",
        "# Predicted: 16882.143\r\n",
        "# https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}